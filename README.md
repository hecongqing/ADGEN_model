# Qwenå¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆå™¨

åŸºäºQwen3å¤§è¯­è¨€æ¨¡å‹çš„æ™ºèƒ½å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆç³»ç»Ÿï¼Œæ”¯æŒLoRAå¾®è°ƒã€vLLMé«˜æ€§èƒ½æ¨ç†å’Œå¯è§†åŒ–ç•Œé¢ã€‚

## ğŸš€ åŠŸèƒ½ç‰¹ç‚¹

- ğŸ¯ **åŸºäºQwen3æ¨¡å‹**: ä½¿ç”¨å…ˆè¿›çš„Qwen2.5-7B-Instructæ¨¡å‹
- ğŸš€ **LoRAå¾®è°ƒ**: é«˜æ•ˆçš„å‚æ•°å¾®è°ƒï¼Œæ”¯æŒ8bité‡åŒ–
- ğŸ“Š **AdvertiseGenæ•°æ®é›†**: è‡ªåŠ¨åŠ è½½ModelScopeä¸Šçš„å¹¿å‘Šæ–‡æ¡ˆæ•°æ®é›†
- ğŸŒ **vLLMæ¨ç†æœåŠ¡**: é«˜æ€§èƒ½æ¨¡å‹æ¨ç†æœåŠ¡
- ğŸ¨ **Gradioç•Œé¢**: å‹å¥½çš„Webå¯è§†åŒ–ç•Œé¢
- ğŸ”„ **æ‰¹é‡ç”Ÿæˆ**: æ”¯æŒå•ä¸ªå’Œæ‰¹é‡æ–‡æ¡ˆç”Ÿæˆ
- ğŸ“ˆ **å¯è°ƒå‚æ•°**: æ”¯æŒæ¸©åº¦ã€top-pç­‰ç”Ÿæˆå‚æ•°è°ƒèŠ‚

## ğŸ“ é¡¹ç›®ç»“æ„

```
â”œâ”€â”€ dataset/                # æ•°æ®é›†ç¼“å­˜ç›®å½•
â”œâ”€â”€ outputs/                # æ¨¡å‹è¾“å‡ºç›®å½•
â”œâ”€â”€ configs/                # é…ç½®æ–‡ä»¶
â”‚   â””â”€â”€ training_config.yaml
â”œâ”€â”€ scripts/                # å¯åŠ¨è„šæœ¬
â”‚   â”œâ”€â”€ train.sh           # è®­ç»ƒè„šæœ¬
â”‚   â”œâ”€â”€ start_service.sh   # å¯åŠ¨æ¨ç†æœåŠ¡
â”‚   â””â”€â”€ start_app.sh       # å¯åŠ¨åº”ç”¨ç•Œé¢
â”œâ”€â”€ service/               # vLLMæ¨ç†æœåŠ¡
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ vllm_service.py
â”œâ”€â”€ src/                   # æºä»£ç 
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ app.py            # Gradioåº”ç”¨ç•Œé¢
â”‚   â”œâ”€â”€ dataset.py        # æ•°æ®é›†å¤„ç†
â”‚   â”œâ”€â”€ model.py          # æ¨¡å‹å®šä¹‰å’Œæ¨ç†
â”‚   â”œâ”€â”€ train.py          # è®­ç»ƒè„šæœ¬
â”‚   â””â”€â”€ utils.py          # å·¥å…·å‡½æ•°
â”œâ”€â”€ requirements.txt       # ä¾èµ–åŒ…åˆ—è¡¨
â””â”€â”€ README.md             # é¡¹ç›®è¯´æ˜
```

## ğŸ› ï¸ å®‰è£…ä¾èµ–

```bash
# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt

# å¦‚æœä½¿ç”¨GPUï¼Œç¡®ä¿å®‰è£…CUDAç‰ˆæœ¬çš„PyTorch
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```

## ğŸ“š ä½¿ç”¨è¯´æ˜

### 1. æ¨¡å‹è®­ç»ƒ

#### æ–¹æ³•1: ä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°è®­ç»ƒ
./scripts/train.sh

# è‡ªå®šä¹‰å‚æ•°è®­ç»ƒ
MODEL_NAME="Qwen/Qwen2.5-7B-Instruct" \
OUTPUT_DIR="./my_model" \
EPOCHS=5 \
BATCH_SIZE=8 \
./scripts/train.sh
```

#### æ–¹æ³•2: ç›´æ¥è¿è¡ŒPython

```bash
# åŸºç¡€è®­ç»ƒ
python -m src.train \
    --model_name "Qwen/Qwen2.5-7B-Instruct" \
    --output_dir "./outputs" \
    --num_train_epochs 3 \
    --per_device_train_batch_size 4 \
    --learning_rate 5e-5 \
    --use_lora \
    --use_8bit \
    --test_after_train

# ä½¿ç”¨æœ¬åœ°æ•°æ®é›†
python -m src.train \
    --dataset_path "./my_dataset.json" \
    --model_name "Qwen/Qwen2.5-7B-Instruct" \
    --output_dir "./outputs"
```

### 2. å¯åŠ¨æ¨ç†æœåŠ¡

#### æ–¹æ³•1: ä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨é»˜è®¤å‚æ•°å¯åŠ¨
./scripts/start_service.sh

# è‡ªå®šä¹‰å‚æ•°å¯åŠ¨
MODEL_PATH="./outputs" \
PORT=8080 \
TENSOR_PARALLEL_SIZE=2 \
./scripts/start_service.sh
```

#### æ–¹æ³•2: ç›´æ¥è¿è¡ŒPython

```bash
python service/vllm_service.py \
    --model_path "./outputs" \
    --host "0.0.0.0" \
    --port 8000 \
    --tensor_parallel_size 1 \
    --gpu_memory_utilization 0.9
```

### 3. å¯åŠ¨Webåº”ç”¨

#### æ–¹æ³•1: ä½¿ç”¨è„šæœ¬ï¼ˆæ¨èï¼‰

```bash
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
./scripts/start_app.sh

# ä½¿ç”¨è¿œç¨‹æœåŠ¡
USE_LOCAL_MODEL=false \
SERVICE_URL="http://localhost:8000" \
./scripts/start_app.sh

# åˆ›å»ºå…¬å…±é“¾æ¥
SHARE=true ./scripts/start_app.sh
```

#### æ–¹æ³•2: ç›´æ¥è¿è¡ŒPython

```bash
# ä½¿ç”¨æœ¬åœ°æ¨¡å‹
python -m src.app \
    --model_path "./outputs" \
    --use_local_model \
    --server_port 7860

# ä½¿ç”¨è¿œç¨‹æœåŠ¡
python -m src.app \
    --service_url "http://localhost:8000" \
    --server_port 7860
```

## ğŸ¯ APIä½¿ç”¨

### æ¨ç†æœåŠ¡API

å¯åŠ¨æ¨ç†æœåŠ¡åï¼Œå¯ä»¥é€šè¿‡HTTP APIè°ƒç”¨ï¼š

```python
import requests

# å•ä¸ªç”Ÿæˆ
response = requests.post("http://localhost:8000/generate", json={
    "prompt": "ç±»å‹#è£™*ç‰ˆå‹#æ˜¾ç˜¦*æè´¨#ç½‘çº±*é£æ ¼#æ€§æ„Ÿ*å›¾æ¡ˆ#è•¾ä¸",
    "max_new_tokens": 256,
    "temperature": 0.7,
    "top_p": 0.9,
    "repetition_penalty": 1.1
})

result = response.json()
print(result["generated_text"])

# æ‰¹é‡ç”Ÿæˆ
response = requests.post("http://localhost:8000/batch_generate", json={
    "prompts": [
        "ç±»å‹#è£™*ç‰ˆå‹#æ˜¾ç˜¦*æè´¨#ç½‘çº±*é£æ ¼#æ€§æ„Ÿ",
        "ç±»å‹#è£¤*ç‰ˆå‹#å®½æ¾*æè´¨#ç‰›ä»”*é¢œè‰²#è“è‰²"
    ],
    "max_new_tokens": 256,
    "temperature": 0.7,
    "top_p": 0.9
})

results = response.json()
for result in results:
    print(result["generated_text"])
```

### æœ¬åœ°æ¨¡å‹ä½¿ç”¨

```python
from src.model import QwenAdvertiseGenerator

# åˆå§‹åŒ–ç”Ÿæˆå™¨
generator = QwenAdvertiseGenerator()

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
generator.load_model()

# æˆ–åŠ è½½å¾®è°ƒæ¨¡å‹
# generator.load_finetuned_model("./outputs")

# ç”Ÿæˆæ–‡æ¡ˆ
content = "ç±»å‹#è£™*ç‰ˆå‹#æ˜¾ç˜¦*æè´¨#ç½‘çº±*é£æ ¼#æ€§æ„Ÿ*å›¾æ¡ˆ#è•¾ä¸"
result = generator.generate_text(
    content,
    max_new_tokens=256,
    temperature=0.7,
    top_p=0.9
)
print(result)
```

## ğŸ“Š æ•°æ®æ ¼å¼

### è¾“å…¥æ ¼å¼

å¹¿å‘Šæ–‡æ¡ˆç”Ÿæˆçš„è¾“å…¥æ ¼å¼ä¸ºï¼š`å±æ€§#å€¼*å±æ€§#å€¼*...`

å¸¸ç”¨å±æ€§åŒ…æ‹¬ï¼š
- **ç±»å‹**: è£™ã€è£¤ã€ä¸Šè¡£ã€é‹ã€åŒ…ç­‰
- **ç‰ˆå‹**: æ˜¾ç˜¦ã€å®½æ¾ã€ä¿®èº«ã€ç›´ç­’ç­‰
- **æè´¨**: ç½‘çº±ã€ç‰›ä»”ã€æ£‰ã€çš®é©ã€å¸†å¸ƒç­‰
- **é£æ ¼**: æ€§æ„Ÿã€ä¼‘é—²ã€ç®€çº¦ã€å•†åŠ¡ã€æ–‡è‰ºç­‰
- **é¢œè‰²**: è“è‰²ã€ç™½è‰²ã€é»‘è‰²ã€ç±³è‰²ç­‰
- **å›¾æ¡ˆ**: è•¾ä¸ã€é•‚ç©ºã€çº¯è‰²ã€æ ¼å­ç­‰

### ç¤ºä¾‹

```
è¾“å…¥: ç±»å‹#è£™*ç‰ˆå‹#æ˜¾ç˜¦*æè´¨#ç½‘çº±*é£æ ¼#æ€§æ„Ÿ*å›¾æ¡ˆ#è•¾ä¸*å›¾æ¡ˆ#é•‚ç©º*å›¾æ¡ˆ#çº¯è‰²*è£™ä¸‹æ‘†#é±¼å°¾*è£™é•¿#è¿è¡£è£™
è¾“å‡º: æ€§æ„Ÿé•‚ç©ºè•¾ä¸ç½‘çº±é±¼å°¾è¿è¡£è£™ï¼Œæ˜¾ç˜¦ç‰ˆå‹ï¼Œçº¯è‰²è®¾è®¡ï¼Œä¼˜é›…è¿·äººã€‚

è¾“å…¥: ç±»å‹#è£¤*ç‰ˆå‹#å®½æ¾*æè´¨#ç‰›ä»”*é¢œè‰²#è“è‰²*é£æ ¼#ä¼‘é—²*æ¬¾å¼#ç›´ç­’
è¾“å‡º: è“è‰²å®½æ¾ç›´ç­’ç‰›ä»”è£¤ï¼Œä¼‘é—²èˆ’é€‚ï¼Œç™¾æ­æ—¶å°šå•å“ã€‚
```

## ğŸ”§ é…ç½®è¯´æ˜

ä¸»è¦é…ç½®æ–‡ä»¶ `configs/training_config.yaml`:

```yaml
# æ•°æ®é›†é…ç½®
dataset:
  name: "AdvertiseGen"
  source: "modelscope"
  max_length: 512

# æ¨¡å‹é…ç½®
model:
  name: "Qwen/Qwen2.5-7B-Instruct"
  use_lora: true
  use_8bit: true

# LoRAé…ç½®
lora:
  r: 16
  lora_alpha: 32
  lora_dropout: 0.1

# è®­ç»ƒé…ç½®
training:
  num_train_epochs: 3
  per_device_train_batch_size: 4
  learning_rate: 5.0e-5
  
# ç”Ÿæˆé…ç½®
generation:
  max_new_tokens: 256
  temperature: 0.7
  top_p: 0.9
```

## ğŸ“ˆ æ€§èƒ½ä¼˜åŒ–

### GPUå†…å­˜ä¼˜åŒ–

1. **8bité‡åŒ–**: å‡å°‘çº¦50%çš„GPUå†…å­˜ä½¿ç”¨
2. **LoRAå¾®è°ƒ**: åªè®­ç»ƒå°‘é‡å‚æ•°ï¼Œå¤§å¹…å‡å°‘å†…å­˜éœ€æ±‚
3. **æ¢¯åº¦ç´¯ç§¯**: é€šè¿‡`gradient_accumulation_steps`æ¨¡æ‹Ÿæ›´å¤§çš„batch size

### æ¨ç†ä¼˜åŒ–

1. **vLLMåŠ é€Ÿ**: ä½¿ç”¨vLLMè¿›è¡Œé«˜æ€§èƒ½æ¨ç†
2. **æ‰¹é‡å¤„ç†**: æ”¯æŒæ‰¹é‡ç”Ÿæˆæé«˜ååé‡
3. **å¼ é‡å¹¶è¡Œ**: å¤šGPUç¯å¢ƒä¸‹ä½¿ç”¨`tensor_parallel_size`

## ğŸ› å¸¸è§é—®é¢˜

### 1. CUDAå†…å­˜ä¸è¶³

```bash
# å‡å°batch size
--per_device_train_batch_size 2

# ä½¿ç”¨æ¢¯åº¦ç´¯ç§¯
--gradient_accumulation_steps 2

# å¯ç”¨8bité‡åŒ–
--use_8bit
```

### 2. æ¨¡å‹åŠ è½½å¤±è´¥

```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la ./outputs/

# æ£€æŸ¥æ¨¡å‹æ–‡ä»¶
ls -la ./outputs/pytorch_model.bin

# é‡æ–°ä¸‹è½½æ¨¡å‹
rm -rf ./dataset/models--Qwen--Qwen2.5-7B-Instruct
```

### 3. vLLMæœåŠ¡å¯åŠ¨å¤±è´¥

```bash
# æ£€æŸ¥GPUå¯ç”¨æ€§
nvidia-smi

# é™ä½GPUå†…å­˜åˆ©ç”¨ç‡
--gpu_memory_utilization 0.7

# ä½¿ç”¨CPUæ¨¡å¼ï¼ˆå¼€å‘æµ‹è¯•ï¼‰
export CUDA_VISIBLE_DEVICES=""
```

## ğŸ“ å¼€å‘è¯´æ˜

### æ·»åŠ æ–°çš„æ•°æ®å¤„ç†åŠŸèƒ½

ä¿®æ”¹ `src/dataset.py` ä¸­çš„ `AdvertiseGenDataset` ç±»ï¼š

```python
def custom_preprocess(self, examples):
    # è‡ªå®šä¹‰é¢„å¤„ç†é€»è¾‘
    pass
```

### è‡ªå®šä¹‰æ¨¡å‹é…ç½®

ä¿®æ”¹ `src/model.py` ä¸­çš„ `QwenAdvertiseGenerator` ç±»ï¼š

```python
def _setup_generation_config(self):
    # è‡ªå®šä¹‰ç”Ÿæˆé…ç½®
    pass
```

### æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡

ä¿®æ”¹ `src/utils.py` ä¸­çš„ `calculate_metrics` å‡½æ•°ï¼š

```python
def calculate_metrics(predictions, references):
    # æ·»åŠ æ–°çš„è¯„ä¼°æŒ‡æ ‡
    pass
```

## ğŸ¤ è´¡çŒ®æŒ‡å—

1. Fork é¡¹ç›®
2. åˆ›å»ºç‰¹æ€§åˆ†æ”¯ (`git checkout -b feature/AmazingFeature`)
3. æäº¤æ›´æ”¹ (`git commit -m 'Add some AmazingFeature'`)
4. æ¨é€åˆ°åˆ†æ”¯ (`git push origin feature/AmazingFeature`)
5. å¼€å¯ Pull Request

## ğŸ“„ è®¸å¯è¯

æœ¬é¡¹ç›®é‡‡ç”¨ MIT è®¸å¯è¯ã€‚è¯¦è§ [LICENSE](LICENSE) æ–‡ä»¶ã€‚

## ğŸ™ è‡´è°¢

- [Qwen](https://github.com/QwenLM/Qwen) - åŸºç¡€è¯­è¨€æ¨¡å‹
- [vLLM](https://github.com/vllm-project/vllm) - é«˜æ€§èƒ½æ¨ç†å¼•æ“
- [Gradio](https://github.com/gradio-app/gradio) - Webç•Œé¢æ¡†æ¶
- [ModelScope](https://modelscope.cn/) - æ•°æ®é›†å’Œæ¨¡å‹ä»“åº“